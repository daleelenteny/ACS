{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 1 \n",
    "'''\n",
    "Select an individual feature by attribute value from one feature class, then select features from another feature class by distance from the original feature. \n",
    "Originally used for selecting census block groups within a specified distance of a point feature. \n",
    "'''\n",
    "def select_feature_by_attribute(focus_features, focus_field, focus_value): \n",
    "    \n",
    "    # Construct SQL \n",
    "    sql = f\"{focus_field} = '{focus_value}'\"\n",
    "\n",
    "    # Apply attribute selection \n",
    "    focus_selection, count          = arcpy.management.SelectLayerByAttribute(focus_features, 'NEW_SELECTION', sql)\n",
    "    if count == '0': \n",
    "        print('No focus features selected')\n",
    "    elif count != '1': \n",
    "        pass\n",
    "    else: \n",
    "        print('Multiple features selected')\n",
    "        \n",
    "    return focus_selection\n",
    "    \n",
    "def export_block_groups_by_distance(geo_features, focus_selection, selection_distance, output_folder, output_name): \n",
    "    \n",
    "    # Select by distance \n",
    "    target_selection, merge, count  = arcpy.management.SelectLayerByLocation(geo_features, 'WITHIN_A_DISTANCE', focus_selection, selection_distance, 'NEW_SELECTION')\n",
    "    print(f'Selected  : {count} features')\n",
    "    \n",
    "    # Clip if needed \n",
    "    if clip == True: \n",
    "        clip_selection = r\"memory/clip\" \n",
    "        arcpy.analysis.Clip(target_selection, clip_features, clip_selection)\n",
    "    \n",
    "    # Designate output path \n",
    "    geo_output   = os.path.join(output_folder, output_name + '.shp')\n",
    "    \n",
    "    # Export target selection \n",
    "    if arcpy.Exists(geo_output) and overwrite == True or arcpy.Exists(geo_output) == False: \n",
    "        arcpy.conversion.ExportFeatures(clip_selection, geo_output)\n",
    "    elif arcpy.Exists(geo_output) and overwrite == False: \n",
    "        pass \n",
    "    \n",
    "    return geo_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 2 \n",
    "'''\n",
    "Return variables dictionary from JSON url. \n",
    "'''\n",
    "def read_census_json(json_url): \n",
    "    \n",
    "    # Make a GET request to the JSON url \n",
    "    response = requests.get(json_url)\n",
    "    \n",
    "    # Check if it was successful (status code == 200)\n",
    "    if response.status_code == 200: \n",
    "        \n",
    "        # This is the initial response, in dictionary form \n",
    "        json_dict = response.json()\n",
    "        \n",
    "        # There is only one key, so reassign the dictionary variable to that key \n",
    "        json_dictionary = json_dict['variables']\n",
    "    \n",
    "    else: \n",
    "        print(\"Couldn't read JSON\")\n",
    "    \n",
    "    return json_dictionary\n",
    "\n",
    "'''\n",
    "Parse the dictionary so that it is intelligible. \n",
    "This includes all concepts, and will be filtered by an input group code or concept in the next function.\n",
    "'''\n",
    "def return_group_dictionary(json_dictionary): \n",
    "    \n",
    "    # Initialize count \n",
    "    count = 0 \n",
    "    \n",
    "    # Initialize dictionaries \n",
    "    group_dictionary            = {} \n",
    "    \n",
    "    # Iterate through JSON dictionary \n",
    "    for code, values in json_dictionary.items(): \n",
    "        \n",
    "        try:\n",
    "            # Identify group variable \n",
    "            group   = values['group']\n",
    "            \n",
    "            # Initialize dictionary key for group \n",
    "            if group not in group_dictionary.keys() and \",\" not in group: \n",
    "                group_dictionary[group]            = {} \n",
    "                group_dictionary[group]['concept'] = []\n",
    "                group_dictionary[group]['codes']   = []\n",
    "            else: \n",
    "                pass\n",
    "            \n",
    "        except: \n",
    "            pass \n",
    "        \n",
    "        try: \n",
    "            # Identify concept variable \n",
    "            concept = values['concept']\n",
    "            \n",
    "            # Initialize dictionary key for group \n",
    "            group_dictionary[group]['concept'] = concept\n",
    "            group_dictionary[group]['codes'].append(code)\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    if group_dictionary != {}: \n",
    "        pass\n",
    "    else: \n",
    "        print('Group dictionary empty')\n",
    "        \n",
    "    return group_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 3 \n",
    "'''\n",
    "Return a list of variable codes based on a designated group code. \n",
    "'''\n",
    "def find_variable_codes(input_group_code, group_dictionary): \n",
    "    \n",
    "    # For group code, concept/codes dictionary\n",
    "    for group_code, concept_codes_dict in group_dictionary.items(): \n",
    "        if group_code == input_group_code: \n",
    "            variable_codes = concept_codes_dict['codes']\n",
    "            \n",
    "    return variable_codes \n",
    "\n",
    "'''\n",
    "This creates a dictionary of codes and their values. \n",
    "'''\n",
    "def create_code_label_dictionary(variable_codes, json_dictionary): \n",
    "    \n",
    "    code_label_dictionary = {} \n",
    "    code_label_dictionary['B01001_001E'] = 'Total Population'\n",
    "\n",
    "    for code in variable_codes: \n",
    "        label = json_dictionary[code]['label'].split('!!')[-1]\n",
    "        code_label_dictionary[code] = label \n",
    "\n",
    "    return code_label_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 4\n",
    "'''\n",
    "Create variable string. \n",
    "'''\n",
    "\n",
    "def create_variable_string(variable_codes): \n",
    "    \n",
    "    # Initialize empty variable string \n",
    "    variable_string = r\"NAME,B01001_001E\"\n",
    "\n",
    "    # Iterate through filtered dictionary \n",
    "    for code in variable_codes: \n",
    "        variable_string = variable_string + ',' + code\n",
    "    \n",
    "    return variable_string \n",
    "\n",
    "'''\n",
    "Use the geographic field attributes of the feature classes to create a list of urls \n",
    "'''\n",
    "def construct_api_urls(geo_output, api_key, variable_string): \n",
    "    \n",
    "    api_urls = []\n",
    "    \n",
    "    with arcpy.da.SearchCursor(geo_output, ['STATE_FIPS', 'COUNTY_FIP', 'TRACT_FIPS', 'BLOCKGROUP']) as cursor: \n",
    "        for row in cursor: \n",
    "            state       = row[0]\n",
    "            county      = row[1] \n",
    "            tract       = row[2] \n",
    "            block_group = row[3] \n",
    "\n",
    "            var_clause    = fr\"https://api.census.gov/data/2022/acs/acs5?get={variable_string}\"\n",
    "            geo_clause    = fr\"&for=block%20group:{block_group}&in=state:{state}%20county:{county}%20tract:{tract}\"\n",
    "            key_clause    = fr\"&key={api_key}\"\n",
    "\n",
    "            api_url       = var_clause + geo_clause + key_clause\n",
    "            api_urls.append(api_url)\n",
    "        \n",
    "    return api_urls\n",
    "\n",
    "'''\n",
    "Iterate through API URLs and receive dictionary of responses \n",
    "'''\n",
    "\n",
    "def send_api_calls(api_urls): \n",
    "    \n",
    "    # Initialize variables\n",
    "    time_1  = time.time() \n",
    "    json_list = [] \n",
    "    url_count = 0\n",
    "\n",
    "    # Send API call \n",
    "    for url in api_urls: \n",
    "        url_count += 1 \n",
    "\n",
    "        print('---------------')\n",
    "        print(f'Call #{url_count} / {len(api_urls)}')\n",
    "        print('---------------')\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200: \n",
    "            json_list.append(response.json())\n",
    "            print(f'>>> Status:       Good')\n",
    "        else: \n",
    "            print('>>> Error: ', response.status_code)\n",
    "\n",
    "        # Measure and print elapsed time \n",
    "        time_2  = time.time() \n",
    "        elapsed = round(time_2 - time_1, 2) \n",
    "        print(f'>>> Elapsed time: {elapsed}')\n",
    "        \n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 5 \n",
    "'''\n",
    "Converts output of API calls to dataframe. Index is created from variables, rows each represent a block group. \n",
    "'''\n",
    "\n",
    "def json_list_to_dataframe(json_list):\n",
    "\n",
    "    output_dictionary = {} \n",
    "    \n",
    "    index_list = json_list[0][0]\n",
    "    \n",
    "    for index in index_list: \n",
    "        output_dictionary[index] = []\n",
    "\n",
    "    for json in json_list: \n",
    "        values = json[1]\n",
    "\n",
    "        for i, value in enumerate(values): \n",
    "            output_dictionary[index_list[i]].append(value)\n",
    "\n",
    "    api_dataframe = pd.DataFrame.from_dict(output_dictionary)\n",
    "    api_dataframe = api_dataframe.rename(columns = code_label_dictionary)\n",
    "    \n",
    "    api_dataframe['FIPS'] = api_dataframe['state'] + api_dataframe['county'] + api_dataframe['tract'] + api_dataframe['block group']\n",
    "    \n",
    "    return api_dataframe \n",
    "\n",
    "'''\n",
    "Change columns to integers if value is numeric. \n",
    "'''\n",
    "def change_columns_to_integers(dataframe): \n",
    "    \n",
    "    for column in dataframe.columns: \n",
    "\n",
    "        try: \n",
    "            dataframe[column] = dataframe[column].astype(int)\n",
    "        except: \n",
    "            pass\n",
    "            \n",
    "    return dataframe \n",
    "\n",
    "'''\n",
    "Calculate percentage columns. \n",
    "'''\n",
    "def calculate_percentage_columns(dataframe):\n",
    "    \n",
    "    # Iterate through columns \n",
    "    for column in dataframe.columns:\n",
    "        \n",
    "        # If it is in the dictionary\n",
    "        if column in code_label_dictionary.values(): \n",
    "            \n",
    "            # Identify the column's position  \n",
    "            column_position = dataframe.columns.get_loc(column) + 1\n",
    "            # Calculate its value\n",
    "            percentage_formula = (dataframe[column]/dataframe['Total Population'])*100\n",
    "            # Insert the new column \n",
    "            dataframe.insert(column_position, f'% {column}', round(percentage_formula, 2))\n",
    "            \n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 6\n",
    "'''\n",
    "Merge API data with geometry, drop unnecessary columns, and export to a shapefile. \n",
    "'''\n",
    "def merge_and_export_geodataframe(geo_output, api_dataframe, keep_columns, output_folder, merge_label): \n",
    "    \n",
    "    # Initialize spatial dataframe from feature class \n",
    "    geodataframe = gpd.read_file(geo_output)\n",
    "\n",
    "    # Merge \n",
    "    merge_geodataframe = geodataframe.merge(api_dataframe, on = 'FIPS', how = 'left')\n",
    "\n",
    "    # Drop \n",
    "    for column in merge_geodataframe.columns: \n",
    "        if column not in keep_columns: \n",
    "            merge_geodataframe.drop(columns = column, inplace = True)\n",
    "\n",
    "    # Export to shapefile \n",
    "    merge_shp = os.path.join(output_folder, merge_label) \n",
    "    merge_geodataframe.to_file(output_folder + merge_label)\n",
    "    \n",
    "    return merge_shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_shapefile_and_geodataframe(geo_output, api_dataframe, join_field): \n",
    "    \n",
    "    # Initialize spatial dataframe from feature class \n",
    "    geodataframe = gpd.read_file(geo_output)\n",
    "\n",
    "    # Merge \n",
    "    merge_geodataframe = geodataframe.merge(api_dataframe, on = join_field, how = 'left')\n",
    "    \n",
    "    return merge_geodataframe \n",
    "\n",
    "def drop_dataframe_columns(merge_geodataframe, keep_columns):\n",
    "    \n",
    "    # Drop \n",
    "    for column in merge_geodataframe.columns: \n",
    "        if column not in keep_columns: \n",
    "            merge_geodataframe.drop(columns = column, inplace = True)\n",
    "            \n",
    "    return merge_geodataframe \n",
    "\n",
    "def export_gdf_to_shapefile(merge_geodataframe, output_folder, merge_shp_label): \n",
    "    \n",
    "    # Export to shapefile \n",
    "    merge_shp = os.path.join(output_folder, merge_shp_label + '.shp') \n",
    "    merge_geodataframe.to_file(merge_shp, 'ESRI Shapefile')\n",
    "    \n",
    "    return merge_shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 7\n",
    "'''\n",
    "Add to map\n",
    "'''\n",
    "def identify_layer(mp_name, output_shp): \n",
    "\n",
    "    # Identify layer \n",
    "    aprx = arcpy.mp.ArcGISProject('CURRENT')\n",
    "    mp   = aprx.listMaps(mp_name)[0]\n",
    "    lyr  = mp.addDataFromPath(output_shp)\n",
    "\n",
    "    return lyr \n",
    "\n",
    "def identify_color_ramp(color_ramp_name): \n",
    "    \n",
    "    # Find color ramp \n",
    "    aprx = arcpy.mp.ArcGISProject('CURRENT')\n",
    "    \n",
    "    try: \n",
    "        color_ramp = aprx.listColorRamps(color_ramp_name)[0]\n",
    "    except: \n",
    "        print('Color ramp not found')\n",
    "        \n",
    "    return color_ramp \n",
    "\n",
    "'''\n",
    "Apply unclassed symbology \n",
    "'''\n",
    "def apply_unclassed_symbology(layer, sym_field, color_ramp, lower_label, upper_label): \n",
    "\n",
    "    # Identify map \n",
    "    aprx = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "\n",
    "    # Initialize weighted_symbology \n",
    "    symbology = layer.symbology \n",
    "\n",
    "    # Define weighted Colors Renderer\n",
    "    if symbology.renderer.type != \"UnclassedColorsRenderer\": \n",
    "        symbology.updateRenderer(\"UnclassedColorsRenderer\")\n",
    "    else: \n",
    "        pass\n",
    "    \n",
    "    symbology.renderer.field               = sym_field \n",
    "    symbology.renderer.colorRamp           = color_ramp \n",
    "    symbology.renderer.lowerLabel          = lower_label\n",
    "    symbology.renderer.upperLabel          = upper_label\n",
    "    \n",
    "    # Outline color \n",
    "    symbology.renderer.symbolTemplate.outlineColor = {'RGB': [0, 0, 0, 100]}\n",
    "    symbology.renderer.symbolTemplate.outlineWidth = 1\n",
    "\n",
    "    # Apply symbology \n",
    "    layer.symbology = symbology\n",
    "    \n",
    "    return symbology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Composite \n",
    "'''\n",
    "\n",
    "# Census 2 \n",
    "def retrieve_acs_json(json_url): \n",
    "    \n",
    "    json_dictionary  = read_census_json(json_url)\n",
    "    group_dictionary = return_group_dictionary(json_dictionary)\n",
    "    \n",
    "    return json_dictionary, group_dictionary\n",
    "\n",
    "# Census 3 \n",
    "def retrieve_acs_dictionary(input_group_code, group_dictionary, json_dictionary): \n",
    "    \n",
    "    variable_codes        = find_variable_codes(input_group_code, group_dictionary)\n",
    "    code_label_dictionary = create_code_label_dictionary(variable_codes, json_dictionary)\n",
    "    \n",
    "    return variable_codes, code_label_dictionary \n",
    "\n",
    "# Census 4 \n",
    "def census_api(variable_codes, geo_output, api_key): \n",
    "    \n",
    "    variable_string = create_variable_string(variable_codes)\n",
    "    api_urls        = construct_api_urls(geo_output, api_key, variable_string)\n",
    "    json_list       = send_api_calls(api_urls)\n",
    "    \n",
    "    return variable_string, json_list \n",
    "\n",
    "# Census 5\n",
    "def create_api_dataframe(json_list): \n",
    "\n",
    "    api_dataframe = json_list_to_dataframe(json_list)\n",
    "    api_dataframe = change_columns_to_integers(api_dataframe)\n",
    "    api_dataframe = calculate_percentage_columns(api_dataframe)\n",
    "    \n",
    "    return api_dataframe\n",
    "\n",
    "# Census 6 \n",
    "def create_output_geodataframe(geo_output, api_dataframe, output_folder, output_label, keep_columns):\n",
    "    \n",
    "    output_shp = merge_and_export_geodataframe(geo_output, api_dataframe, output_folder, output_label, keep_columns)\n",
    "    \n",
    "    return output_shp \n",
    "\n",
    "# Census 7 \n",
    "def visualize_acs_data(mp_name, output_shp, color_ramp_name, lower_label, upper_label): \n",
    "    \n",
    "    layer     = identify_layer(mp_name, output_shp)\n",
    "    symbology = apply_unclassed_symbology(layer, color_ramp_name, lower_label, upper_label)\n",
    "    \n",
    "    return layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################################################\n",
    "#####################################################################################################################################################\n",
    "#####################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Master \n",
    "'''\n",
    "\n",
    "# Imports \n",
    "import os \n",
    "import requests \n",
    "import pandas as pd\n",
    "import geopandas as gpd \n",
    "\n",
    "# Flow control \n",
    "create_geo_output   = True \n",
    "make_api_call       = True \n",
    "export_geodataframe = True \n",
    "\n",
    "# Focus point \n",
    "focus_features      = r'C:\\DALE\\Personal\\Minnesota\\MyProject\\ACS.gdb\\Focus_Points'\n",
    "focus_field         = 'NAME'\n",
    "focus_value         = 'SMU Minneapolis'\n",
    "\n",
    "# Block groups      \n",
    "geo_features        = r'C:\\DALE\\Personal\\Minnesota\\GIS Projects\\ACS\\Block_Groups.gdb\\MN'\n",
    "selection_distance  = '20 Miles'\n",
    "output_folder       = r'C:\\DALE\\Personal\\Minnesota\\GIS Projects\\ACS\\Output Data\\Block Group Shapefiles'\n",
    "output_name         = 'White_Alone_Part2'\n",
    "overwrite           = True \n",
    "clip                = True \n",
    "clip_features       = r'C:\\DALE\\Personal\\Minnesota\\GIS Projects\\ACS\\Output Data\\ACS Data\\Metro_White_Alone.shp'\n",
    "\n",
    "# API \n",
    "json_url            = r'https://api.census.gov/data/2022/acs/acs5/variables.json'\n",
    "input_group_code    = 'B02001'\n",
    "api_key             = r'1749dc1d87964116107a80cd7d76fca300dda59f'\n",
    "\n",
    "# Dataframe \n",
    "output_folder       = r'C:\\DALE\\Personal\\Minnesota\\GIS Projects\\ACS\\Output Data\\ACS Data'    \n",
    "merge_shp_label     = 'Metro_White_Alone'\n",
    "join_field          = 'FIPS'\n",
    "keep_columns        = ['FIPS', 'geometry', '% White alone']\n",
    "\n",
    "# Map and Layer\n",
    "mp_name             = 'Census'\n",
    "sym_field           = '% White al'\n",
    "color_ramp_name     = 'White_to_Brown'\n",
    "lower_label         = '100'\n",
    "upper_label         = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple features selected\n",
      "Selected  : 2086 features\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Master Process \n",
    "'''\n",
    "\n",
    "### Create geo output ### \n",
    "if create_geo_output == True: \n",
    "    \n",
    "    focus_selection = select_feature_by_attribute(focus_features, focus_field, focus_value)\n",
    "    geo_output      = export_block_groups_by_distance(geo_features, focus_selection, selection_distance, output_folder, output_name, overwrite, clip, clip_features)\n",
    "\n",
    "else: \n",
    "    geo_output                        = os.path.join(output_folder, output_name)\n",
    "    print('1: Block groups shapefile already exists:')\n",
    "    print(output_folder, output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Call API ### \n",
    "if make_api_call == True: \n",
    "    \n",
    "    # Retrieve concepts JSON \n",
    "    json_dictionary, group_dictionary     = retrieve_acs_json(json_url)\n",
    "    print(\"2: Retrieved ACS json\")\n",
    "\n",
    "    # Retrieve list of codes based on concept \n",
    "    variable_codes, code_label_dictionary = retrieve_acs_dictionary(input_group_code, group_dictionary, json_dictionary)\n",
    "    print(\"3: Retrieved ACS codes\")\n",
    "    \n",
    "    # Create variable string \n",
    "    variable_string = create_variable_string(variable_codes)\n",
    "    \n",
    "    # Create list of API urls \n",
    "    api_urls        = construct_api_urls(geo_output, api_key, variable_string)\n",
    "    \n",
    "    # Call API if designated\n",
    "    print('URLs returned: ', len(api_urls))\n",
    "    print('Continue?')\n",
    "    x = input() \n",
    "    \n",
    "    if x != \"\": \n",
    "        pass \n",
    "    else: \n",
    "        # Call the API \n",
    "        json_list       = send_api_calls(api_urls)\n",
    "        print(\"4: Called Census API and retrieved data\")\n",
    "\n",
    "    # Create dataframe\n",
    "    api_dataframe                         = create_api_dataframe(json_list)\n",
    "    print(\"5: Converted API response to dataframe\")\n",
    "\n",
    "### Export geodataframe ### \n",
    "if export_geodataframe == True: \n",
    "    \n",
    "    # Merge API dataframe with block groups, drop unnecessary columns, and export to shapefile \n",
    "    merge_geodataframe = merge_shapefile_and_geodataframe(geo_output, api_dataframe, join_field)\n",
    "    merge_geodataframe = drop_dataframe_columns(merge_geodataframe, keep_columns)\n",
    "    merge_shp          = export_gdf_to_shapefile(merge_geodataframe, output_folder, merge_shp_label)\n",
    "\n",
    "    print(\"6: Export dataframe to shapefile\")\n",
    "    print(f\" {merge_shp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################################################\n",
    "#####################################################################################################################################################\n",
    "#####################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dir(symbology.renderer.symbolTemplate): \n",
    "    if d.startswith(\"_\") == False: \n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbology.renderer.symbolTemplate.outlineColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find color ramp \n",
    "for cr in aprx.listColorRamps(): \n",
    "    if cr.name == 'White_to_Brown': \n",
    "        print(cr.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add to map ### \n",
    "layer      = identify_layer(mp_name, merge_shp)\n",
    "color_ramp = identify_color_ramp(color_ramp_name)\n",
    "symbology  = apply_unclassed_symbology(layer, sym_field, color_ramp, lower_label, upper_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
