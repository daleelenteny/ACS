{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 1 \n",
    "'''\n",
    "Select an individual feature by attribute value from one feature class, then select features from another feature class by distance from the original feature. \n",
    "Originally used for selecting census block groups within a specified distance of a point feature. \n",
    "'''\n",
    "def select_feature_by_attribute(focus_features, focus_field, focus_value): \n",
    "    \n",
    "    # Construct SQL \n",
    "    sql = f\"{focus_field} = '{focus_value}'\"\n",
    "\n",
    "    # Apply attribute selection \n",
    "    focus_selection, count          = arcpy.management.SelectLayerByAttribute(focus_features, 'NEW_SELECTION', sql)\n",
    "    if count == '0': \n",
    "        print('No focus features selected')\n",
    "    elif count != '1': \n",
    "        pass\n",
    "    else: \n",
    "        print('Multiple features selected')\n",
    "        \n",
    "    return focus_selection\n",
    "    \n",
    "def export_block_groups_by_distance(geo_features, focus_selection, selection_distance, output_folder, output_name, overwrite): \n",
    "    \n",
    "    # Select by distance \n",
    "    target_selection, merge, count  = arcpy.management.SelectLayerByLocation(geo_features, 'WITHIN_A_DISTANCE', focus_selection, selection_distance, 'NEW_SELECTION')\n",
    "    print(f'Selected  : {count} features')\n",
    "    \n",
    "    # Designate output path \n",
    "    geo_output   = os.path.join(output_folder, output_name + '.shp')\n",
    "    \n",
    "    # Export target selection \n",
    "    if arcpy.Exists(geo_output) and overwrite == True or arcpy.Exists(geo_output) == False: \n",
    "        arcpy.conversion.ExportFeatures(target_selection, geo_output)\n",
    "    elif arcpy.Exists(geo_output) and overwrite == False: \n",
    "        pass \n",
    "    \n",
    "    return geo_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 2 \n",
    "'''\n",
    "Return variables dictionary from JSON url. \n",
    "'''\n",
    "def read_census_json(json_url): \n",
    "    \n",
    "    # Make a GET request to the JSON url \n",
    "    response = requests.get(json_url)\n",
    "    \n",
    "    # Check if it was successful (status code == 200)\n",
    "    if response.status_code == 200: \n",
    "        \n",
    "        # This is the initial response, in dictionary form \n",
    "        json_dict = response.json()\n",
    "        \n",
    "        # There is only one key, so reassign the dictionary variable to that key \n",
    "        json_dictionary = json_dict['variables']\n",
    "    \n",
    "    else: \n",
    "        print(\"Couldn't read JSON\")\n",
    "    \n",
    "    return json_dictionary\n",
    "\n",
    "'''\n",
    "Parse the dictionary so that it is intelligible. \n",
    "This includes all concepts, and will be filtered by an input group code or concept in the next function.\n",
    "'''\n",
    "def return_group_dictionary(json_dictionary): \n",
    "    \n",
    "    # Initialize count \n",
    "    count = 0 \n",
    "    \n",
    "    # Initialize dictionaries \n",
    "    group_dictionary            = {} \n",
    "    \n",
    "    # Iterate through JSON dictionary \n",
    "    for code, values in json_dictionary.items(): \n",
    "        \n",
    "        try:\n",
    "            # Identify group variable \n",
    "            group   = values['group']\n",
    "            \n",
    "            # Initialize dictionary key for group \n",
    "            if group not in group_dictionary.keys() and \",\" not in group: \n",
    "                group_dictionary[group]            = {} \n",
    "                group_dictionary[group]['concept'] = []\n",
    "                group_dictionary[group]['codes']   = []\n",
    "            else: \n",
    "                pass\n",
    "            \n",
    "        except: \n",
    "            pass \n",
    "        \n",
    "        try: \n",
    "            # Identify concept variable \n",
    "            concept = values['concept']\n",
    "            \n",
    "            # Initialize dictionary key for group \n",
    "            group_dictionary[group]['concept'] = concept\n",
    "            group_dictionary[group]['codes'].append(code)\n",
    "\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    if group_dictionary != {}: \n",
    "        pass\n",
    "    else: \n",
    "        print('Group dictionary empty')\n",
    "        \n",
    "    return group_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 3 \n",
    "'''\n",
    "Return a list of variable codes based on a designated group code. \n",
    "'''\n",
    "def find_variable_codes(input_group_code, group_dictionary): \n",
    "    \n",
    "    # For group code, concept/codes dictionary\n",
    "    for group_code, concept_codes_dict in group_dictionary.items(): \n",
    "        if group_code == input_group_code: \n",
    "            variable_codes = concept_codes_dict['codes']\n",
    "            \n",
    "    return variable_codes \n",
    "\n",
    "'''\n",
    "This creates a dictionary of codes and their values. \n",
    "'''\n",
    "def create_code_label_dictionary(variable_codes, json_dictionary): \n",
    "    \n",
    "    code_label_dictionary = {} \n",
    "    code_label_dictionary['B01001_001E'] = 'Total Population'\n",
    "\n",
    "    for code in variable_codes: \n",
    "        label = json_dictionary[code]['label'].split('!!')[-1]\n",
    "        code_label_dictionary[code] = label \n",
    "\n",
    "    return code_label_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 4\n",
    "'''\n",
    "Create variable string. \n",
    "'''\n",
    "\n",
    "def create_variable_string(variable_codes): \n",
    "    \n",
    "    # Initialize empty variable string \n",
    "    variable_string = r\"NAME,B01001_001E\"\n",
    "\n",
    "    # Iterate through filtered dictionary \n",
    "    for code in variable_codes: \n",
    "        variable_string = variable_string + ',' + code\n",
    "    \n",
    "    return variable_string \n",
    "\n",
    "'''\n",
    "Use the geographic field attributes of the feature classes to create a list of urls \n",
    "'''\n",
    "def construct_api_urls(geo_output, api_key, variable_string): \n",
    "    \n",
    "    api_urls = []\n",
    "    \n",
    "    with arcpy.da.SearchCursor(geo_output, ['STATE_FIPS', 'COUNTY_FIP', 'TRACT_FIPS', 'BLOCKGROUP']) as cursor: \n",
    "        for row in cursor: \n",
    "            state       = row[0]\n",
    "            county      = row[1] \n",
    "            tract       = row[2] \n",
    "            block_group = row[3] \n",
    "\n",
    "            var_clause    = fr\"https://api.census.gov/data/2022/acs/acs5?get={variable_string}\"\n",
    "            geo_clause    = fr\"&for=block%20group:{block_group}&in=state:{state}%20county:{county}%20tract:{tract}\"\n",
    "            key_clause    = fr\"&key={api_key}\"\n",
    "\n",
    "            api_url       = var_clause + geo_clause + key_clause\n",
    "            api_urls.append(api_url)\n",
    "        \n",
    "    return api_urls\n",
    "\n",
    "'''\n",
    "Iterate through API URLs and receive dictionary of responses \n",
    "'''\n",
    "\n",
    "def send_api_calls(api_urls): \n",
    "    \n",
    "    # Initialize variables\n",
    "    time_1  = time.time() \n",
    "    json_list = [] \n",
    "    url_count = 0\n",
    "\n",
    "    # Send API call \n",
    "    for url in api_urls: \n",
    "        url_count += 1 \n",
    "\n",
    "        print('---------------')\n",
    "        print(f'Call #{url_count} / {len(api_urls)}')\n",
    "        print('---------------')\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200: \n",
    "            json_list.append(response.json())\n",
    "            print(f'>>> Status:       Good')\n",
    "        else: \n",
    "            print('>>> Error: ', response.status_code)\n",
    "\n",
    "        # Measure and print elapsed time \n",
    "        time_2  = time.time() \n",
    "        elapsed = round(time_2 - time_1, 2) \n",
    "        print(f'>>> Elapsed time: {elapsed}')\n",
    "\n",
    "        if url_count > 2: \n",
    "            break \n",
    "        \n",
    "    return json_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 5 \n",
    "'''\n",
    "Converts output of API calls to dataframe. Index is created from variables, rows each represent a block group. \n",
    "'''\n",
    "\n",
    "def json_list_to_dataframe(json_list):\n",
    "\n",
    "    output_dictionary = {} \n",
    "    \n",
    "    index_list = json_list[0][0]\n",
    "    \n",
    "    for index in index_list: \n",
    "        output_dictionary[index] = []\n",
    "\n",
    "    for json in json_list: \n",
    "        values = json[1]\n",
    "\n",
    "        for i, value in enumerate(values): \n",
    "            output_dictionary[index_list[i]].append(value)\n",
    "\n",
    "    api_dataframe = pd.DataFrame.from_dict(output_dictionary)\n",
    "    api_dataframe = api_dataframe.rename(columns = code_label_dictionary)\n",
    "    \n",
    "    api_dataframe['FIPS'] = api_dataframe['state'] + api_dataframe['county'] + api_dataframe['tract'] + api_dataframe['block group']\n",
    "    \n",
    "    return api_dataframe \n",
    "\n",
    "'''\n",
    "Change columns to integers if value is numeric. \n",
    "'''\n",
    "def change_columns_to_integers(dataframe): \n",
    "    \n",
    "    for column in dataframe.columns: \n",
    "\n",
    "        try: \n",
    "            dataframe[column] = dataframe[column].astype(int)\n",
    "        except: \n",
    "            pass\n",
    "            \n",
    "    return dataframe \n",
    "\n",
    "'''\n",
    "Calculate percentage columns. \n",
    "'''\n",
    "def calculate_percentage_columns(dataframe):\n",
    "    \n",
    "    # Iterate through columns \n",
    "    for column in dataframe.columns:\n",
    "        \n",
    "        # If it is in the dictionary\n",
    "        if column in code_label_dictionary.values(): \n",
    "            \n",
    "            # Identify the column's position  \n",
    "            column_position = dataframe.columns.get_loc(column) + 1\n",
    "            # Calculate its value\n",
    "            percentage_formula = (dataframe[column]/dataframe['Total Population'])*100\n",
    "            # Insert the new column \n",
    "            dataframe.insert(column_position, f'% {column}', round(percentage_formula, 2))\n",
    "            \n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 6\n",
    "'''\n",
    "Merge API data with geometry, drop unnecessary columns, and export to a shapefile. \n",
    "'''\n",
    "def merge_and_export_geodataframe(geo_output, api_dataframe, keep_columns, out_folder, output_label): \n",
    "    \n",
    "    # Initialize spatial dataframe from feature class \n",
    "    geodataframe = gpd.read_file(geo_output)\n",
    "\n",
    "    # Merge \n",
    "    merge_geodataframe = geodataframe.merge(api_dataframe, on = 'FIPS', how = 'left')\n",
    "\n",
    "    # Drop \n",
    "    for column in merge_geodataframe.columns: \n",
    "        if column not in keep_columns: \n",
    "            merge_geodataframe.drop(columns = column, inplace = True)\n",
    "\n",
    "    # Export to shapefile \n",
    "    output_shp = os.path.join(out_folder, output_label) \n",
    "    merge_geodataframe.to_file(out_folder + output_label)\n",
    "    \n",
    "    return output_shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Census 7\n",
    "'''\n",
    "Add to map\n",
    "'''\n",
    "def identify_layer(mp_name, output_shp): \n",
    "\n",
    "    # Identify layer \n",
    "    aprx = arcpy.mp.ArcGISProject('CURRENT')\n",
    "    mp   = aprx.listMaps(mp_name)[0]\n",
    "    lyr  = mp.addDataFromPath(output_shp)\n",
    "\n",
    "    return lyr \n",
    "\n",
    "'''\n",
    "Apply unclassed symbology \n",
    "'''\n",
    "def apply_unclassed_symbology(layer, color_ramp_name, lower_label, upper_label): \n",
    "\n",
    "    # Identify map \n",
    "    aprx = arcpy.mp.ArcGISProject(\"CURRENT\")\n",
    "\n",
    "    # Initialize weighted_symbology \n",
    "    symbology = layer.symbology \n",
    "\n",
    "    # Define weighted Colors Renderer\n",
    "    if symbology.renderer.type != \"UnclassedColorsRenderer\": \n",
    "        symbology.updateRenderer(\"UnclassedColorsRenderer\")\n",
    "    else: \n",
    "        pass\n",
    "\n",
    "    symbology.renderer.colorRamp           = aprx.listColorRamps(color_ramp_name)[0]\n",
    "    symbology.renderer.lowerLabel          = lower_label\n",
    "    symbology.renderer.upperLabel          = upper_label\n",
    "\n",
    "    # Apply symbology \n",
    "    layer.symbology = symbology\n",
    "    \n",
    "    return symbology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Composite \n",
    "'''\n",
    "# Census 1\n",
    "def export_block_groups(focus_features, focus_field, focus_value, geo_features, selection_distance, output_folder, output_name, overwrite):\n",
    "\n",
    "    focus_selection = select_feature_by_attribute(focus_features, focus_field, focus_value)\n",
    "    geo_output      = export_block_groups_by_distance(geo_features, focus_selection, selection_distance, output_folder, output_name, overwrite)\n",
    "    \n",
    "    return geo_output \n",
    "\n",
    "# Census 2 \n",
    "def retrieve_acs_json(json_url): \n",
    "    \n",
    "    json_dictionary  = read_census_json(json_url)\n",
    "    group_dictionary = return_group_dictionary(json_dictionary)\n",
    "    \n",
    "    return json_dictionary, group_dictionary\n",
    "\n",
    "# Census 3 \n",
    "def retrieve_acs_dictionary(input_group_code, group_dictionary, json_dictionary): \n",
    "    \n",
    "    variable_codes        = find_variable_codes(input_group_code, group_dictionary)\n",
    "    code_label_dictionary = create_code_label_dictionary(variable_codes, json_dictionary)\n",
    "    \n",
    "    return variable_codes, code_label_dictionary \n",
    "\n",
    "# Census 4 \n",
    "def census_api(variable_codes, geo_output, api_key): \n",
    "    \n",
    "    variable_string = create_variable_string(variable_codes)\n",
    "    api_urls        = construct_api_urls(geo_output, api_key, variable_string)\n",
    "    json_list       = send_api_calls(api_urls)\n",
    "    \n",
    "    return variable_string, json_list \n",
    "\n",
    "# Census 5\n",
    "def create_api_dataframe(json_list): \n",
    "\n",
    "    api_dataframe = json_list_to_dataframe(json_list)\n",
    "    api_dataframe = change_columns_to_integers(api_dataframe)\n",
    "    api_dataframe = calculate_percentage_columns(api_dataframe)\n",
    "    \n",
    "    return api_dataframe\n",
    "\n",
    "# Census 6 \n",
    "def create_output_geodataframe(geo_output, api_dataframe, output_folder, output_label, keep_columns):\n",
    "    \n",
    "    output_shp = merge_and_export_geodataframe(geo_output, api_dataframe, output_folder, output_label, keep_columns)\n",
    "    \n",
    "    return output_shp \n",
    "\n",
    "# Census 7 \n",
    "def visualize_acs_data(mp_name, output_shp, color_ramp_name, lower_label, upper_label): \n",
    "    \n",
    "    layer     = identify_layer(mp_name, output_shp)\n",
    "    symbology = apply_unclassed_symbology(layer, color_ramp_name, lower_label, upper_label)\n",
    "    \n",
    "    return layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Master \n",
    "'''\n",
    "\n",
    "# Imports \n",
    "import os \n",
    "import requests \n",
    "import pandas as pd\n",
    "import geopandas as gpd \n",
    "\n",
    "# Focus point \n",
    "focus_features      = r'C:\\DALE\\Personal\\Minnesota\\MyProject\\ACS.gdb\\Focus_Points'\n",
    "focus_field         = 'NAME'\n",
    "focus_value         = 'Wilder'\n",
    "\n",
    "# Block groups      \n",
    "geo_features        = r'C:\\DALE\\Personal\\Minnesota\\GIS Projects\\ACS\\Block_Groups.gdb\\MN'\n",
    "selection_distance  = '1 Mile'\n",
    "output_folder       = r'C:\\DALE\\Personal\\Minnesota\\GIS Projects\\ACS\\Output Data\\Block Group Shapefiles'\n",
    "output_name         = 'Wilder_1_Mile'\n",
    "overwrite           = True \n",
    "\n",
    "# API \n",
    "json_url            = r'https://api.census.gov/data/2022/acs/acs5/variables.json'\n",
    "input_group_code    = 'B02001'\n",
    "api_key             = r'1749dc1d87964116107a80cd7d76fca300dda59f'\n",
    "\n",
    "# Dataframe \n",
    "output_label        = 'Metro_White_Alone.shp'\n",
    "keep_columns        = ['FIPS', 'geometry', '% White alone']\n",
    "\n",
    "# Map and Layer\n",
    "mp_name             = 'Census'\n",
    "color_ramp_name     = 'Brown 3'\n",
    "lower_label         = '100'\n",
    "upper_label         = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple features selected\n",
      "Selected  : 20 features\n",
      "1: Exported block groups\n",
      "2: Retrieved ACS json\n",
      "3: Retrieved ACS codes\n",
      "---------------\n",
      "Call #1 / 20\n",
      "---------------\n",
      ">>> Status:       Good\n",
      ">>> Elapsed time: 2.55\n",
      "---------------\n",
      "Call #2 / 20\n",
      "---------------\n",
      ">>> Status:       Good\n",
      ">>> Elapsed time: 4.82\n",
      "---------------\n",
      "Call #3 / 20\n",
      "---------------\n",
      ">>> Status:       Good\n",
      ">>> Elapsed time: 6.11\n",
      "4: Called Census API and retrieved data\n",
      "5: Converted API response to dataframe\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "join() argument must be str, bytes, or os.PathLike object, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "In  \u001b[0;34m[108]\u001b[0m:\nLine \u001b[0;34m13\u001b[0m:    output_shp                            = create_output_geodataframe(geo_output, api_dataframe, output_folder, output_label, keep_columns)\u001b[37m\u001b[39;49;00m\n",
      "In  \u001b[0;34m[106]\u001b[0m:\nLine \u001b[0;34m49\u001b[0m:    output_shp = merge_and_export_geodataframe(geo_output, api_dataframe, output_folder, output_label, keep_columns)\u001b[37m\u001b[39;49;00m\n",
      "In  \u001b[0;34m[104]\u001b[0m:\nLine \u001b[0;34m19\u001b[0m:    output_shp = os.path.join(out_folder, output_label) \u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Users\\delenteny\\AppData\\Local\\ESRI\\conda\\envs\\custom-env\\lib\\ntpath.py\u001b[0m, in \u001b[0;32mjoin\u001b[0m:\nLine \u001b[0;34m117\u001b[0m:   genericpath._check_arg_types(\u001b[33m'\u001b[39;49;00m\u001b[33mjoin\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, path, *paths)\u001b[37m\u001b[39;49;00m\n",
      "File \u001b[0;34mC:\\Users\\delenteny\\AppData\\Local\\ESRI\\conda\\envs\\custom-env\\lib\\genericpath.py\u001b[0m, in \u001b[0;32m_check_arg_types\u001b[0m:\nLine \u001b[0;34m152\u001b[0m:   \u001b[34mraise\u001b[39;49;00m \u001b[36mTypeError\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfuncname\u001b[33m}\u001b[39;49;00m\u001b[33m() argument must be str, bytes, or \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: join() argument must be str, bytes, or os.PathLike object, not 'list'\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Master Function \n",
    "    \n",
    "geo_output                            = export_block_groups(focus_features, focus_field, focus_value, geo_features, selection_distance, output_folder, output_name, overwrite)\n",
    "print(\"1: Exported block groups\")\n",
    "json_dictionary, group_dictionary     = retrieve_acs_json(json_url)\n",
    "print(\"2: Retrieved ACS json\")\n",
    "variable_codes, code_label_dictionary = retrieve_acs_dictionary(input_group_code, group_dictionary, json_dictionary)\n",
    "print(\"3: Retrieved ACS codes\")\n",
    "json_list                             = send_api_calls(api_urls)\n",
    "print(\"4: Called Census API and retrieved data\")\n",
    "api_dataframe                         = create_api_dataframe(json_list)\n",
    "print(\"5: Converted API response to dataframe\")\n",
    "output_shp                            = create_output_geodataframe(geo_output, api_dataframe, output_folder, output_label, keep_columns)\n",
    "print(\"6: Export dataframe to shapefile\")\n",
    "layer                                 = visualize_acs_data(mp_name, output_shp, color_ramp_name, lower_label, upper_label)\n",
    "print(\"7: Added layer to map\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
